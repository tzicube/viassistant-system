Phân Tích Workspace ViProject
1. Danh Sách Thư Mục & File Quan Trọng
Backend (backend)
Core Django Config
config/settings.py — Cấu hình Django: DB (MySQL), CORS, WebSocket (Daphne), Ollama API, AI System Prompt
config/asgi.py — ASGI entrypoint: gộp WebSocket routes từ chatapp & vitranslation
config/urls.py — URL routing chính
manage.py — Django management entrypoint
Chat Module (chatapp/)
chatapp/views.py — HTTP endpoints: create_conversation, chat_stream, translate_audio; streaming responses via Ollama
chatapp/consumers.py — WebSocket consumer (ViChatConsumer): real-time chat delta streaming
chatapp/routing.py — WebSocket URL pattern: /ws/vichat/
chatapp/models.py — DB models: Conversation, Message, AppMemory (chưa show, nhưng được dùng)
chatapp/memory.py — Helper: get_app_memory, format_app_memory_text, get_history_messages
chatapp/urls.py — HTTP routes: /api/creatnew, /api/conversations, /api/chat/stream
ViTranslation Module (vitranslation/)
ViRecord Realtime Translation (vitranslation/virecord/)
virecord/consumers.py — WebSocket consumer: 3 parallel async lines (STT, Translation realtime, Summary 10s)
virecord/routing.py — WebSocket URL: /ws/virecord/
virecord/memory.py — SessionMemory dataclass: trạng thái session (STT, translate, context)
virecord/history_fs.py — File system I/O: new_session, read/write source/target, build_title_context_tail
virecord/urls.py — HTTP API: /api/new_topic, /api/record_history, /api/record_detail
virecord/views.py — HTTP handlers (chưa show chi tiết)
AI Engine (vitranslation/ai_engine/)
ai_engine/translator.py — Async translation: stream_translate_segment_async(), final_translate_full()
ai_engine/summarizer.py — Summary generation: make_summary()
ai_engine/ollama_client.py — (chưa show) Ollama HTTP client: generate(), generate_stream()
ai_engine/prompts.py — Prompt builders: translate_segment_prompt(), final_translate_prompt(), summary_prompt()
ai_engine/config.py — Ollama config: URL, model, timeout
STT Engine (stt_engine/)
stt_engine/stream.py — RealtimeWhisperStreamer: buffer PCM16, transcribe mỗi ~0.8s
stt_engine/whisper_gpu.py — (chưa show) Whisper inference: transcribe_wav()
stt_engine/config.py — WhisperConfig dataclass
History Storage
vitranslation/history/ — Folder tree: mỗi session = YYYY-MM-DD_HH-MM-SS/ chứa:
meta.json — title_id, title_name, created_at
source.txt — source text (lines)
target.txt — translated text (lines)
Frontend (frontend)
Chat App (chat/)
chat/chat.html — Main UI: sidebar (history), topbar, messages, input
chat/chat.js — Main logic: WS client (ViChatConsumer), CRUD conversations, streaming delta messages
chat/chat.css — Dark theme, responsive layout, animations
ViRecord App (virecord/)
virecord/virecord.html — Dashboard: lang selector, source/target cards, session history
virecord/virecord.js — (chưa show chi tiết) WS client (ViRecordConsumer), audio recording, realtime display
virecord/virecord.css — (chưa show chi tiết) Layout & styling
Root Docs
vi.txt — Specification: flow diagram, endpoints, requirements cho 2 apps (Chat & ViRecord)
git.gitignore — (hoặc .gitignore) Ignore patterns
2. Công Dụng Chi Tiết (Per File)
File	Công Dụng
settings.py	DB config, CORS, Ollama, AI system prompt
asgi.py	WebSocket routing + Django HTTP
consumers.py	Real-time chat via WS: build messages, stream Ollama
views.py	HTTP: POST create conversation, GET history, SSE stream chat
consumers.py	3 parallel tasks: STT (Whisper), Translate (realtime), Summary (10s)
history_fs.py	File CRUD: session folder, source/target append, context tail
translator.py	Async call Ollama translate (segment + final)
prompts.py	Jinja-like templates: prompt builders
stream.py	Buffer PCM → WAV → Whisper (mỗi 0.8s)
chat.js (FE)	WS connect, message UI, CRUD conversation
virecord.js (FE)	WS connect, audio record, realtime delta display
3. Kiến Trúc Tổng Thể & Luồng Xử Lý Chính
Kiến Trúc
┌─────────────────────────────────────────────────────────┐
│                   Frontend (2 Apps)                       │
│  ┌──────────────────┐  ┌──────────────────────────────┐  │
│  │   chat/          │  │  virecord/                   │  │
│  │  HTML + JS + CSS │  │  HTML + JS + CSS             │  │
│  │  (Chat WS)       │  │  (ViRecord WS + Audio)       │  │
│  └─────────┬────────┘  └──────────┬───────────────────┘  │
└────────────┼──────────────────────┼────────────────────────┘
             │ WS /ws/vichat/       │ WS /ws/virecord/
             │ + HTTP /api/         │ + Audio chunks
             │                      │
┌────────────▼──────────────────────▼────────────────────────┐
│              Backend (Django + Daphne)                      │
│                                                              │
│  ┌─────────────────────┐    ┌──────────────────────────┐   │
│  │  Chat Module        │    │  ViTranslation Module    │   │
│  │  ┌─────────────────┐│    │  ┌────────────────────┐  │   │
│  │  │ ViChatConsumer  ││    │  │ ViRecordConsumer   │  │   │
│  │  │ (WS: delta)     ││    │  │ (WS: 3x parallel)  │  │   │
│  │  ├─────────────────┤│    │  │                    │  │   │
│  │  │ views.py        ││    │  │ [Line1] STT        │  │   │
│  │  │ (HTTP)          ││    │  │ [Line2] Translate  │  │   │
│  │  └─────────────────┘│    │  │ [Line3] Summary    │  │   │
│  └─────────────────────┘    │  └────────────────────┘  │   │
│                              │                          │   │
│           ┌──────────────────┴──────────────────────┐   │   │
│           │     AI Engine (Shared)                  │   │   │
│           │  ├─ translator.py (Ollama stream)      │   │   │
│           │  ├─ summarizer.py (Ollama gen)        │   │   │
│           │  ├─ prompts.py (Prompt builders)      │   │   │
│           │  └─ ollama_client.py (HTTP)           │   │   │
│           │                                        │   │   │
│           │     STT Engine (Realtime)             │   │   │
│           │  ├─ stream.py (PCM buffer)            │   │   │
│           │  └─ whisper_gpu.py (Inference)        │   │   │
│           └─────────────────────────────────────────┘   │   │
│                                                          │   │
│           ┌──────────────────────────────────────────┐   │   │
│           │  History FS (File System)                │   │   │
│           │  vitranslation/history/YYYY-MM-DD.../   │   │   │
│           │  ├─ meta.json                           │   │   │
│           │  ├─ source.txt                          │   │   │
│           │  └─ target.txt                          │   │   │
│           └──────────────────────────────────────────┘   │   │
└──────────────────────────────────────────────────────────┘   │
             │                        │
             ▼                        ▼
    ┌──────────────────┐    ┌───────────────────┐
    │  MySQL DB        │    │  Ollama (LLM)     │
    │  (Conversations, │    │  (gemma2:9b)      │
    │   Messages)      │    │                   │
    └──────────────────┘    └───────────────────┘
    Luồng Chính
Flow 1: Chat (ViChatConsumer)
FE WS → {type: "chat.send", text}
  │
  ├─ HTTP POST /api/creatnew (if new conversation)
  │   └─ Create conversation + first assistant message
  │
  └─ WS stream (if existing conversation)
      ├─ Save user message to DB
      ├─ Load history + format prompt (system + app_memory + history)
      ├─ Call Ollama stream_translate_segment_async()
      │  └─ Yield token by token
      ├─ Send WS {type: "chat.delta", text_delta: "..."}
      ├─ Save assistant message to DB
      └─ Send WS {type: "chat.done"}
Flow 2: ViRecord (ViRecordConsumer)
FE WS → {type: "init", title_id, stt_language, translate_source, translate_target}
  │
  ├─ Spawn 3 parallel async tasks:
  │
  │  [Line 1] STT (mỗi 0.8s)
  │  ├─ Receive {type: "audio.chunk", pcm16_b64}
  │  ├─ Push to Whisper streamer
  │  ├─ transcribe_cumulative() → stt_full
  │  └─ Send WS {type: "stt.delta", delta: "..."}
  │
  │  [Line 2] Realtime Translation
  │  ├─ Poll stt_cumulative (new segment)
  │  ├─ Call stream_translate_segment_async() (async)
  │  │  └─ Prompt includes: title_context_tail + summary_context
  │  └─ Send WS {type: "translation.delta", delta: "..."}
  │
  │  [Line 3] Summary (every 10s)
  │  ├─ Build combined source (committed + live)
  │  ├─ Call make_summary() → AI summarize
  │  └─ Send WS {type: "summary.update", summary: "..."}
  │
  └─ On {type: "stop"}
      ├─ Wait 0.4s (grace time)
      ├─ Build full_src (committed + live)
      ├─ Call final_translate_full() (final re-translate)
      ├─ Write source.txt + target.txt
      ├─ Save title_context_tail for next session
      ├─ Send WS {type: "final.result", source, target, summary}
      └─ Shutdown tasks
4. File Entrypoint, Core Logic, I/O, Realtime
Entrypoint
Backend: manage.py → runs via daphne (ASGI)
Frontend:
Chat: chat/chat.html + chat/chat.js
ViRecord: virecord/virecord.html + virecord/virecord.js
Core Logic
Chat AI: chatapp/consumers.py (ViChatConsumer)
ViRecord Translation: vitranslation/virecord/consumers.py (ViRecordConsumer)
Ollama Integration: vitranslation/ai_engine/translator.py (stream_translate_segment_async, final_translate_full)
I/O
HTTP: chatapp/views.py, vitranslation/virecord/views.py
File System: vitranslation/virecord/history_fs.py
Database: Models in chatapp/models.py (Conversation, Message, AppMemory)
Realtime
WebSocket Consumers:
chatapp/consumers.py — chat delta streaming
vitranslation/virecord/consumers.py — 3-line parallel streaming (STT + Translation + Summary)
Async Helpers:
vitranslation/ai_engine/translator.py — stream_translate_segment_async() (threading + asyncio queue)
stt_engine/stream.py — RealtimeWhisperStreamer (buffer + cumulative transcribe)
=== ADDITIONAL CONTEXT ===

- Ollama URL: http://127.0.0.1:11434 (gemma2:9b)
- MySQL: root@127.0.0.1:3306/vichat
- Frontend: http://127.0.0.1:5500 (Live Server)
- Backend: http://127.0.0.1:8000 (Daphne)
- WebSocket: ws://127.0.0.1:8000/ws/vichat/ & ws://127.0.0.1:8000/ws/virecord/